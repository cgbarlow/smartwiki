# AWS Bedrock Knowledge Base: RAG Implementation Patterns & Best Practices

## üéØ RAG Systems Expert Research
*Comprehensive guide to implementing production-ready RAG systems with AWS Bedrock Knowledge Base*

## üèóÔ∏è Core RAG Architecture Patterns

### 1. Basic RAG Pattern
```
User Query ‚Üí Embedding ‚Üí Vector Search ‚Üí Document Retrieval ‚Üí Context Augmentation ‚Üí LLM ‚Üí Response
                ‚Üì
        Knowledge Base Vector Store
```

### 2. Advanced RAG with Amazon Bedrock
```
User Query ‚Üí Query Reformulation ‚Üí Semantic/Hierarchical Search ‚Üí Reranking ‚Üí Context Filtering ‚Üí LLM ‚Üí Response with Citations
                     ‚Üì                           ‚Üì                    ‚Üì
            Bedrock Knowledge Base        Vector Database        Source Attribution
```

### 3. Multimodal RAG Pattern
```
Text + Images + Tables ‚Üí Multimodal Embedding ‚Üí Vector Search ‚Üí Content Retrieval ‚Üí Multimodal Context ‚Üí LLM ‚Üí Rich Response
                                    ‚Üì                              ‚Üì
                          Amazon Bedrock Data Automation    Visual + Textual Content
```

## üìö Advanced Chunking Strategies

### 1. Semantic Chunking Implementation

```python
semantic_chunking_config = {
    "chunkingStrategy": "SEMANTIC",
    "semanticChunkingConfiguration": {
        "maxTokens": 300,
        "bufferSize": 0,
        "breakpointPercentileThreshold": 95  # Higher = more distinguishable sentences required
    }
}

# Best for: Legal documents, technical manuals, academic papers
# Benefits: Preserves semantic meaning, improves retrieval accuracy
# Use cases: When context integrity is critical
```

**Key Features:**
- Analyzes relationships between sentences/paragraphs
- Creates chunks that preserve information integrity
- Uses embedding models to calculate semantic similarity
- Maintains sentence boundaries

### 2. Hierarchical Chunking Implementation

```python
hierarchical_chunking_config = {
    "chunkingStrategy": "HIERARCHICAL",
    "hierarchicalChunkingConfiguration": {
        "levelConfigurations": [
            {
                "maxTokens": 1500  # Parent chunk size
            },
            {
                "maxTokens": 300   # Child chunk size
            }
        ],
        "overlapTokens": 60
    }
}

# Best for: Technical manuals, nested documents, complex structures
# Benefits: Maintains document hierarchy, efficient retrieval
# Use cases: Documents with sections, subsections, and detailed content
```

**Architecture:**
```
Document
‚îú‚îÄ‚îÄ Parent Chunk (1500 tokens)
‚îÇ   ‚îú‚îÄ‚îÄ Child Chunk 1 (300 tokens)
‚îÇ   ‚îú‚îÄ‚îÄ Child Chunk 2 (300 tokens)
‚îÇ   ‚îî‚îÄ‚îÄ Child Chunk 3 (300 tokens)
‚îî‚îÄ‚îÄ Parent Chunk (1500 tokens)
    ‚îú‚îÄ‚îÄ Child Chunk 4 (300 tokens)
    ‚îî‚îÄ‚îÄ Child Chunk 5 (300 tokens)
```

### 3. Custom Lambda Chunking

```python
import json
import boto3
from typing import List, Dict

def lambda_handler(event, context):
    """
    Custom chunking with LangChain/LlamaIndex integration
    """
    # Extract input data
    input_files = event['inputFiles']
    configuration = event.get('configuration', {})
    
    processed_files = []
    
    for file_info in input_files:
        s3_uri = file_info['originalFileLocation']['s3Location']['uri']
        
        # Download and process file
        content = download_from_s3(s3_uri)
        
        # Custom chunking logic
        chunks = custom_chunk_content(content, configuration)
        
        # Add metadata to chunks
        enriched_chunks = add_custom_metadata(chunks, file_info)
        
        # Upload processed chunks
        output_location = upload_chunks_to_s3(enriched_chunks, file_info)
        
        processed_files.append({
            'originalFileLocation': file_info['originalFileLocation'],
            'processedFileLocation': output_location
        })
    
    return {
        'processedFiles': processed_files
    }

def custom_chunk_content(content: str, config: Dict) -> List[Dict]:
    """
    Implement custom chunking with LangChain
    """
    from langchain.text_splitter import RecursiveCharacterTextSplitter
    
    # Configure splitter based on content type
    if config.get('content_type') == 'code':
        splitter = RecursiveCharacterTextSplitter.from_language(
            language='python',
            chunk_size=1000,
            chunk_overlap=100
        )
    else:
        splitter = RecursiveCharacterTextSplitter(
            chunk_size=config.get('chunk_size', 1000),
            chunk_overlap=config.get('chunk_overlap', 200),
            separators=["\n\n", "\n", ".", "!", "?", ",", " ", ""]
        )
    
    chunks = splitter.split_text(content)
    
    return [{"text": chunk, "metadata": {}} for chunk in chunks]

def add_custom_metadata(chunks: List[Dict], file_info: Dict) -> List[Dict]:
    """
    Add custom metadata to each chunk
    """
    for i, chunk in enumerate(chunks):
        chunk['metadata'].update({
            'chunk_index': i,
            'total_chunks': len(chunks),
            'source_file': file_info['originalFileLocation']['s3Location']['uri'],
            'processing_timestamp': datetime.now().isoformat(),
            'custom_tags': extract_custom_tags(chunk['text'])
        })
    
    return chunks
```

## üîç Query Enhancement Patterns

### 1. Query Reformulation

```python
def implement_query_reformulation(
    original_query: str,
    knowledge_base_id: str,
    model_id: str = "anthropic.claude-3-sonnet-20240229-v1:0"
):
    """
    Break down complex queries into sub-queries for better retrieval
    """
    # Query reformulation is built into Bedrock Knowledge Base
    # It automatically breaks down queries into simpler sub-queries
    
    retrieval_config = {
        "type": "KNOWLEDGE_BASE",
        "knowledgeBaseConfiguration": {
            "knowledgeBaseId": knowledge_base_id,
            "modelArn": f"arn:aws:bedrock:us-east-1::foundation-model/{model_id}",
            "retrievalConfiguration": {
                "vectorSearchConfiguration": {
                    "numberOfResults": 10,
                    "overrideSearchType": "HYBRID"  # Combines semantic and keyword search
                }
            },
            "generationConfiguration": {
                "inferenceConfig": {
                    "textInferenceConfig": {
                        "temperature": 0.7,
                        "topP": 0.9,
                        "maxTokens": 1000
                    }
                }
            }
        }
    }
    
    response = bedrock_agent_runtime.retrieve_and_generate(
        input={"text": original_query},
        retrieveAndGenerateConfiguration=retrieval_config
    )
    
    return response
```

### 2. Metadata Filtering Patterns

```python
def advanced_metadata_filtering():
    """
    Implement sophisticated metadata filtering strategies
    """
    
    # Department-based filtering
    department_filter = {
        "equals": {
            "key": "department",
            "value": "engineering"
        }
    }
    
    # Date range filtering
    date_range_filter = {
        "andAll": [
            {
                "greaterThan": {
                    "key": "created_date",
                    "value": "2024-01-01"
                }
            },
            {
                "lessThan": {
                    "key": "created_date",
                    "value": "2024-12-31"
                }
            }
        ]
    }
    
    # Document type and confidence filtering
    quality_filter = {
        "andAll": [
            {
                "in": {
                    "key": "document_type",
                    "value": ["specification", "manual", "guide"]
                }
            },
            {
                "greaterThanOrEquals": {
                    "key": "confidence_score",
                    "value": "0.8"
                }
            }
        ]
    }
    
    # Complex nested filtering
    complex_filter = {
        "orAll": [
            {
                "andAll": [
                    department_filter,
                    {
                        "equals": {
                            "key": "priority",
                            "value": "high"
                        }
                    }
                ]
            },
            {
                "andAll": [
                    {
                        "equals": {
                            "key": "status",
                            "value": "approved"
                        }
                    },
                    quality_filter
                ]
            }
        ]
    }
    
    return complex_filter
```

## üé® Multimodal RAG Implementation

### 1. Multimodal Data Processing with Bedrock Data Automation

```python
def setup_multimodal_rag():
    """
    Configure multimodal RAG with images, tables, and structured data
    """
    
    # Multimodal knowledge base configuration
    multimodal_config = {
        "type": "VECTOR",
        "vectorKnowledgeBaseConfiguration": {
            "embeddingModelArn": "arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-embed-image-v1",
            "embeddingModelConfiguration": {
                "embeddingModelType": "FLOAT32"
            }
        }
    }
    
    # Data source with multimodal parsing
    data_source_config = {
        "type": "S3",
        "s3Configuration": {
            "bucketArn": "arn:aws:s3:::multimodal-documents",
            "inclusionPrefixes": ["images/", "documents/", "tables/"]
        },
        "dataDeletionPolicy": "RETAIN",
        "parsingConfiguration": {
            "parsingStrategy": "BEDROCK_DATA_AUTOMATION",
            "bedrockDataAutomationConfiguration": {
                "parsingPrompt": "Extract all text, tables, and image descriptions. Maintain table structure and provide detailed image captions."
            }
        }
    }
    
    return multimodal_config, data_source_config

def query_multimodal_content(
    knowledge_base_id: str,
    text_query: str,
    image_context: str = None
):
    """
    Query multimodal content with text and optional image context
    """
    
    # Enhanced query with multimodal context
    if image_context:
        enhanced_query = f"""
        Query: {text_query}
        Image Context: {image_context}
        
        Please provide a comprehensive answer that considers both textual and visual information.
        Include relevant tables, charts, or diagrams in your response.
        """
    else:
        enhanced_query = text_query
    
    retrieval_config = {
        "type": "KNOWLEDGE_BASE",
        "knowledgeBaseConfiguration": {
            "knowledgeBaseId": knowledge_base_id,
            "modelArn": "arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-sonnet-20240229-v1:0",
            "retrievalConfiguration": {
                "vectorSearchConfiguration": {
                    "numberOfResults": 15,  # More results for multimodal content
                    "overrideSearchType": "HYBRID"
                }
            }
        }
    }
    
    response = bedrock_agent_runtime.retrieve_and_generate(
        input={"text": enhanced_query},
        retrieveAndGenerateConfiguration=retrieval_config
    )
    
    return extract_multimodal_response(response)

def extract_multimodal_response(response):
    """
    Extract and structure multimodal response data
    """
    result = {
        "answer": response["output"]["text"],
        "session_id": response.get("sessionId"),
        "citations": [],
        "visual_content": [],
        "tables": []
    }
    
    for citation in response.get("citations", []):
        for reference in citation.get("retrievedReferences", []):
            ref_data = {
                "content": reference["content"]["text"],
                "location": reference["location"],
                "metadata": reference.get("metadata", {})
            }
            
            # Categorize content type
            if "image" in ref_data["metadata"].get("content_type", ""):
                result["visual_content"].append(ref_data)
            elif "table" in ref_data["metadata"].get("content_type", ""):
                result["tables"].append(ref_data)
            else:
                result["citations"].append(ref_data)
    
    return result
```

### 2. Structured Data Integration

```python
def setup_structured_data_rag():
    """
    Configure RAG for structured data sources (databases, data warehouses)
    """
    
    # Structured data configuration for SQL databases
    structured_config = {
        "type": "RDS",
        "rdsConfiguration": {
            "resourceArn": "arn:aws:rds:us-east-1:account:cluster:data-warehouse",
            "credentialsSecretArn": "arn:aws:secretsmanager:us-east-1:account:secret:rds-credentials",
            "databaseName": "analytics_db",
            "tableName": "business_metrics",
            "fieldMapping": {
                "vectorField": "embedding",
                "textField": "description",
                "metadataField": "metadata",
                "primaryKeyField": "metric_id"
            }
        }
    }
    
    return structured_config

def query_structured_data(
    knowledge_base_id: str,
    natural_language_query: str
):
    """
    Query structured data using natural language to SQL conversion
    """
    
    # Bedrock automatically converts natural language to SQL
    retrieval_config = {
        "type": "KNOWLEDGE_BASE",
        "knowledgeBaseConfiguration": {
            "knowledgeBaseId": knowledge_base_id,
            "modelArn": "arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-sonnet-20240229-v1:0",
            "retrievalConfiguration": {
                "structuredSearchConfiguration": {
                    "queryString": natural_language_query
                }
            }
        }
    }
    
    response = bedrock_agent_runtime.retrieve_and_generate(
        input={"text": f"Query the database for: {natural_language_query}"},
        retrieveAndGenerateConfiguration=retrieval_config
    )
    
    return response
```

## üìä RAG Evaluation & Optimization

### 1. Comprehensive RAG Evaluation

```python
def setup_rag_evaluation():
    """
    Configure comprehensive RAG evaluation using Amazon Bedrock Evaluations
    """
    
    evaluation_config = {
        "jobName": "rag-evaluation-2024",
        "roleArn": "arn:aws:iam::account:role/BedrockEvaluationRole",
        "customerEncryptionKeyId": "arn:aws:kms:us-east-1:account:key/key-id",
        "jobDescription": "Comprehensive RAG system evaluation",
        "evaluationConfig": {
            "automated": [
                {
                    "datasetMetricConfigs": [
                        {
                            "taskType": "Retrieval",
                            "dataset": {
                                "name": "rag-retrieval-dataset",
                                "datasetLocation": {
                                    "s3Uri": "s3://evaluation-data/retrieval-dataset.jsonl"
                                }
                            },
                            "metricNames": [
                                "ContextRelevance",
                                "ContextCoverage",
                                "CitationPrecision",
                                "CitationCoverage"
                            ]
                        },
                        {
                            "taskType": "RAG",
                            "dataset": {
                                "name": "rag-end-to-end-dataset",
                                "datasetLocation": {
                                    "s3Uri": "s3://evaluation-data/end-to-end-dataset.jsonl"
                                }
                            },
                            "metricNames": [
                                "Correctness",
                                "Completeness",
                                "Faithfulness",
                                "Harmfulness",
                                "AnswerRefusal",
                                "Stereotyping"
                            ]
                        }
                    ]
                }
            ]
        },
        "inferenceConfig": {
            "models": [
                {
                    "bedrockModel": {
                        "modelIdentifier": "anthropic.claude-3-sonnet-20240229-v1:0",
                        "inferenceParams": json.dumps({
                            "temperature": 0.1,
                            "top_p": 0.9,
                            "max_tokens": 2000
                        })
                    }
                }
            ]
        },
        "outputDataConfig": {
            "s3Uri": "s3://evaluation-results/rag-evaluation-output/"
        }
    }
    
    return evaluation_config

def create_evaluation_dataset():
    """
    Create evaluation dataset for RAG system
    """
    
    # Example evaluation dataset format
    evaluation_data = [
        {
            "query": "What are the security best practices for AWS Bedrock?",
            "retrievedReferences": [
                {
                    "content": "AWS Bedrock security best practices include...",
                    "metadata": {"source": "aws-security-guide.pdf"}
                }
            ],
            "groundTruthAnswers": [
                "AWS Bedrock security best practices include IAM roles, encryption, VPC endpoints..."
            ],
            "modelAnswer": "Based on the documentation, AWS Bedrock security best practices include..."
        }
    ]
    
    return evaluation_data
```

### 2. Performance Monitoring & Optimization

```python
def implement_rag_monitoring():
    """
    Implement comprehensive RAG system monitoring
    """
    
    import boto3
    from datetime import datetime, timedelta
    
    cloudwatch = boto3.client('cloudwatch')
    
    # Custom metrics for RAG performance
    def put_custom_metrics(
        knowledge_base_id: str,
        query_latency: float,
        retrieval_accuracy: float,
        user_satisfaction: float
    ):
        """
        Send custom metrics to CloudWatch
        """
        
        metrics = [
            {
                'MetricName': 'QueryLatency',
                'Value': query_latency,
                'Unit': 'Milliseconds',
                'Dimensions': [
                    {
                        'Name': 'KnowledgeBaseId',
                        'Value': knowledge_base_id
                    }
                ]
            },
            {
                'MetricName': 'RetrievalAccuracy',
                'Value': retrieval_accuracy,
                'Unit': 'Percent',
                'Dimensions': [
                    {
                        'Name': 'KnowledgeBaseId',
                        'Value': knowledge_base_id
                    }
                ]
            },
            {
                'MetricName': 'UserSatisfaction',
                'Value': user_satisfaction,
                'Unit': 'Percent',
                'Dimensions': [
                    {
                        'Name': 'KnowledgeBaseId',
                        'Value': knowledge_base_id
                    }
                ]
            }
        ]
        
        cloudwatch.put_metric_data(
            Namespace='AWS/Bedrock/RAG',
            MetricData=metrics
        )
    
    # Performance optimization recommendations
    def analyze_rag_performance(knowledge_base_id: str):
        """
        Analyze RAG performance and provide optimization recommendations
        """
        
        # Get CloudWatch metrics
        end_time = datetime.utcnow()
        start_time = end_time - timedelta(days=7)
        
        response = cloudwatch.get_metric_statistics(
            Namespace='AWS/Bedrock/RAG',
            MetricName='QueryLatency',
            Dimensions=[
                {
                    'Name': 'KnowledgeBaseId',
                    'Value': knowledge_base_id
                }
            ],
            StartTime=start_time,
            EndTime=end_time,
            Period=3600,
            Statistics=['Average', 'Maximum']
        )
        
        avg_latency = sum(point['Average'] for point in response['Datapoints']) / len(response['Datapoints'])
        
        # Generate optimization recommendations
        recommendations = []
        
        if avg_latency > 2000:  # 2 seconds
            recommendations.append("Consider using smaller chunk sizes or reducing numberOfResults")
            recommendations.append("Implement caching for frequently asked questions")
            recommendations.append("Consider using binary embeddings for faster retrieval")
        
        if avg_latency > 5000:  # 5 seconds
            recommendations.append("Critical: Review vector database configuration")
            recommendations.append("Consider using hierarchical chunking for better performance")
            recommendations.append("Implement query result caching")
        
        return {
            "average_latency": avg_latency,
            "recommendations": recommendations
        }
```

## üöÄ Production Deployment Patterns

### 1. Infrastructure as Code (CloudFormation/CDK)

```python
from aws_cdk import (
    Stack,
    aws_bedrock as bedrock,
    aws_s3 as s3,
    aws_iam as iam,
    aws_opensearchserverless as oss
)

class BedrockRAGStack(Stack):
    def __init__(self, scope, construct_id, **kwargs):
        super().__init__(scope, construct_id, **kwargs)
        
        # S3 bucket for data sources
        data_bucket = s3.Bucket(
            self, "RAGDataBucket",
            versioned=True,
            encryption=s3.BucketEncryption.S3_MANAGED,
            block_public_access=s3.BlockPublicAccess.BLOCK_ALL
        )
        
        # OpenSearch Serverless collection
        oss_collection = oss.CfnCollection(
            self, "RAGVectorStore",
            name="rag-vector-store",
            type="VECTORSEARCH",
            description="Vector store for RAG application"
        )
        
        # IAM role for Bedrock Knowledge Base
        bedrock_role = iam.Role(
            self, "BedrockKnowledgeBaseRole",
            assumed_by=iam.ServicePrincipal("bedrock.amazonaws.com"),
            managed_policies=[
                iam.ManagedPolicy.from_aws_managed_policy_name("AmazonBedrockFullAccess")
            ]
        )
        
        # Add S3 permissions
        data_bucket.grant_read(bedrock_role)
        
        # Knowledge Base
        knowledge_base = bedrock.CfnKnowledgeBase(
            self, "RAGKnowledgeBase",
            name="production-rag-kb",
            description="Production RAG Knowledge Base",
            role_arn=bedrock_role.role_arn,
            knowledge_base_configuration={
                "type": "VECTOR",
                "vectorKnowledgeBaseConfiguration": {
                    "embeddingModelArn": "arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-embed-text-v1"
                }
            },
            storage_configuration={
                "type": "OPENSEARCH_SERVERLESS",
                "opensearchServerlessConfiguration": {
                    "collectionArn": oss_collection.attr_arn,
                    "vectorIndexName": "rag-index",
                    "fieldMapping": {
                        "vectorField": "vector",
                        "textField": "text",
                        "metadataField": "metadata"
                    }
                }
            }
        )
        
        # Data Source
        data_source = bedrock.CfnDataSource(
            self, "RAGDataSource",
            knowledge_base_id=knowledge_base.attr_knowledge_base_id,
            name="production-data-source",
            data_source_configuration={
                "type": "S3",
                "s3Configuration": {
                    "bucketArn": data_bucket.bucket_arn,
                    "inclusionPrefixes": ["documents/"]
                }
            },
            chunking_configuration={
                "chunkingStrategy": "SEMANTIC",
                "semanticChunkingConfiguration": {
                    "maxTokens": 300,
                    "breakpointPercentileThreshold": 95
                }
            }
        )
```

### 2. Multi-Environment Deployment

```python
def deploy_multi_environment_rag():
    """
    Deploy RAG system across multiple environments (dev, staging, prod)
    """
    
    environments = {
        "dev": {
            "chunk_size": 200,
            "embedding_model": "amazon.titan-embed-text-v1",
            "retrieval_results": 5,
            "vector_store": "opensearch-dev"
        },
        "staging": {
            "chunk_size": 300,
            "embedding_model": "amazon.titan-embed-text-v1",
            "retrieval_results": 10,
            "vector_store": "opensearch-staging"
        },
        "prod": {
            "chunk_size": 300,
            "embedding_model": "amazon.titan-embed-text-v2",
            "retrieval_results": 15,
            "vector_store": "opensearch-prod"
        }
    }
    
    for env, config in environments.items():
        create_environment_knowledge_base(env, config)

def create_environment_knowledge_base(env: str, config: dict):
    """
    Create knowledge base for specific environment
    """
    
    knowledge_base_config = {
        "name": f"rag-kb-{env}",
        "description": f"RAG Knowledge Base for {env} environment",
        "roleArn": f"arn:aws:iam::account:role/BedrockRole-{env}",
        "knowledgeBaseConfiguration": {
            "type": "VECTOR",
            "vectorKnowledgeBaseConfiguration": {
                "embeddingModelArn": f"arn:aws:bedrock:us-east-1::foundation-model/{config['embedding_model']}"
            }
        },
        "storageConfiguration": {
            "type": "OPENSEARCH_SERVERLESS",
            "opensearchServerlessConfiguration": {
                "collectionArn": f"arn:aws:aoss:us-east-1:account:collection/{config['vector_store']}",
                "vectorIndexName": f"rag-index-{env}",
                "fieldMapping": {
                    "vectorField": "vector",
                    "textField": "text",
                    "metadataField": "metadata"
                }
            }
        }
    }
    
    response = bedrock_agent_client.create_knowledge_base(**knowledge_base_config)
    return response
```

## üìà Performance Optimization Best Practices

### 1. Chunk Size Optimization

```python
def optimize_chunk_size():
    """
    Determine optimal chunk size based on content analysis
    """
    
    content_analysis = {
        "average_document_length": 2500,
        "content_type": "technical_documentation",
        "query_complexity": "medium",
        "retrieval_accuracy_target": 0.85
    }
    
    if content_analysis["content_type"] == "technical_documentation":
        if content_analysis["average_document_length"] > 2000:
            return {
                "strategy": "hierarchical",
                "parent_chunk_size": 1500,
                "child_chunk_size": 300,
                "overlap": 100
            }
        else:
            return {
                "strategy": "semantic",
                "max_tokens": 300,
                "breakpoint_threshold": 95
            }
    
    elif content_analysis["content_type"] == "conversational":
        return {
            "strategy": "fixed_size",
            "chunk_size": 200,
            "overlap_percentage": 10
        }
    
    return {
        "strategy": "semantic",
        "max_tokens": 300,
        "breakpoint_threshold": 90
    }
```

### 2. Caching Strategies

```python
import redis
import hashlib
import json

class RAGCacheManager:
    def __init__(self, redis_host: str, redis_port: int = 6379):
        self.redis_client = redis.Redis(host=redis_host, port=redis_port, decode_responses=True)
        self.cache_ttl = 3600  # 1 hour
    
    def get_cache_key(self, query: str, knowledge_base_id: str, filters: dict = None) -> str:
        """
        Generate cache key for query
        """
        cache_data = {
            "query": query.lower().strip(),
            "kb_id": knowledge_base_id,
            "filters": filters or {}
        }
        
        cache_string = json.dumps(cache_data, sort_keys=True)
        return hashlib.md5(cache_string.encode()).hexdigest()
    
    def get_cached_response(self, cache_key: str) -> dict:
        """
        Retrieve cached response
        """
        cached_data = self.redis_client.get(cache_key)
        if cached_data:
            return json.loads(cached_data)
        return None
    
    def cache_response(self, cache_key: str, response: dict):
        """
        Cache response data
        """
        self.redis_client.setex(
            cache_key,
            self.cache_ttl,
            json.dumps(response)
        )
    
    def cached_rag_query(self, knowledge_base_id: str, query: str, filters: dict = None):
        """
        RAG query with caching
        """
        cache_key = self.get_cache_key(query, knowledge_base_id, filters)
        
        # Check cache first
        cached_response = self.get_cached_response(cache_key)
        if cached_response:
            cached_response['from_cache'] = True
            return cached_response
        
        # Execute RAG query
        response = retrieve_and_generate(
            knowledge_base_id=knowledge_base_id,
            query=query,
            metadata_filters=filters
        )
        
        # Cache the response
        self.cache_response(cache_key, response)
        response['from_cache'] = False
        
        return response
```

## üéØ Best Practices Summary

### Data Preparation
1. **Clean and Structure Data**: Remove irrelevant content, standardize formats
2. **Optimize Metadata**: Add meaningful tags and categories
3. **Choose Right Chunking**: Match strategy to content type and use case
4. **Regular Updates**: Keep knowledge base current with automated syncing

### Performance Optimization
1. **Right-size Components**: Balance accuracy vs latency vs cost
2. **Implement Caching**: Cache frequent queries and results
3. **Monitor Metrics**: Track performance and user satisfaction
4. **Iterative Improvement**: Continuously refine based on evaluation results

### Production Deployment
1. **Infrastructure as Code**: Use CloudFormation/CDK for consistent deployments
2. **Multi-Environment Strategy**: Separate dev, staging, and production
3. **Security Best Practices**: IAM roles, encryption, VPC endpoints
4. **Monitoring & Alerting**: Comprehensive observability and alerting

### Cost Management
1. **Choose Appropriate Models**: Balance capability with cost requirements
2. **Optimize Query Patterns**: Reduce unnecessary API calls
3. **Use Binary Embeddings**: When precision requirements allow
4. **Implement Rate Limiting**: Control usage spikes and costs

---

This comprehensive guide provides the foundation for implementing production-ready RAG systems using AWS Bedrock Knowledge Base. The patterns and practices ensure scalable, secure, and high-performing implementations that can adapt to various use cases and requirements.